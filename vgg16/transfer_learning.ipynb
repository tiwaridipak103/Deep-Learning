{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "t7PD69wbXJeI",
    "outputId": "676b3665-8a58-4a87-af94-be60134ec5c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random as rn\n",
    "#importing tensorflow\n",
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import openCV\n",
    "import cv2\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaqZdpDjXQU6"
   },
   "outputs": [],
   "source": [
    "Y=pd.read_csv(\"labels_final.csv\")\n",
    "\n",
    "#creating 16 folder corresponding to class label\n",
    "for i in range(16):\n",
    "  destination = 'a'+str(i)\n",
    "  if not os.path.isdir(destination):\n",
    "    os.makedirs(destination\n",
    "                \n",
    "#moving images to corresponding class label folder\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "count = 0\n",
    "for i, row in Y.iterrows():\n",
    "  label = row['label']\n",
    "  destination = 'a'+str(label)\n",
    "  file_path = row['path']\n",
    "  if os.path.exists(file_path):\n",
    "    shutil.move(file_path,destination)\n",
    "    print(file_path) \n",
    "#creating 16 folder corresponding to class label\n",
    "for i in range(16):\n",
    "  destination = 'A'+str(i)\n",
    "  if not os.path.isdir(destination):\n",
    "    os.makedirs(destination)\n",
    "\n",
    "\n",
    "folder1 = ['a'+str(i)+'/' for i in range(16)]\n",
    "folder2 = ['A'+str(i)+'/' for i in range(16)]\n",
    "import cv2, os\n",
    "for i in range(16):\n",
    "  for infile in os.listdir(folder1[i]):\n",
    "    print (\"file : \" + infile)\n",
    "    read = cv2.imread(folder1[i] + infile)\n",
    "    outfile = infile.split('.')[0] + '.jpg'\n",
    "    cv2.imwrite(folder2[i]+outfile,read,[int(cv2.IMWRITE_JPEG_QUALITY), 200])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "folder1 = ['A'+str(i)+'/' for i in range(16)]\n",
    "transfer = [['B'+str(i)+'/' for i in range(16)],['C'+str(i)+'/' for i in range(16)]] \n",
    "\n",
    "#moving 30% of total file to testing sub folder\n",
    "for i in range(16):\n",
    "  sub_fol = os.listdir(folder1[i])\n",
    "  count = 0\n",
    "  for i in sub_fol:\n",
    "    count += 1\n",
    "    if count <= len(sub_fol)*0.3:\n",
    "      shutil.move(folder1[i],transfer[0][i])\n",
    "\n",
    "#moving 30% of remaining file to validation sub folder\n",
    "for i in range(16):\n",
    "  sub_fol = os.listdir(folder1[i])\n",
    "  count = 0\n",
    "  for i in sub_fol:\n",
    "    count += 1\n",
    "    if count <= len(sub_fol)*0.3:\n",
    "      shutil.move(folder1[i],transfer[1][i])\n",
    "\n",
    "\n",
    "#creating sub folder for training_data, testing_data and validation_data\n",
    "dir = ['training_data/','testing_data/','validation_data/']\n",
    "for i in range(3):\n",
    "  destination = dir[i]\n",
    "  if not os.path.isdir(destination):\n",
    "    os.makedirs(destination)  \n",
    "\n",
    "#moving folder of type 'a', , 'b' and 'c' to training_data, testing_data and validation_data\n",
    "folders = [['A'+str(i)+'/' for i in range(16)],['B'+str(i)+'/' for i in range(16)],['C'+str(i)+'/' for i in range(16)]]\n",
    "for i ,j in enumerate(folders):\n",
    "  for k in j:\n",
    "    shutil.move(k,dir[i])\n",
    "\n",
    "\n",
    "name = ['letter','form','email','handwritten','advertisement','scientific report','scientific publication','specification',\n",
    "         'file folder','news article','budget' ,'invoice','presentation','questionnaire','resume','memo']\n",
    "folders = [['A'+str(i)+'/' for i in range(16)],['B'+str(i)+'/' for i in range(16)],['C'+str(i)+'/' for i in range(16)]]       \n",
    "for i in range(3):\n",
    "  for j in range(len(name)):\n",
    "    os.rename(folders[i][j],name[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTEIWmxcXXGU",
    "outputId": "1a8c4390-d557-4119-fabd-aa45d5105723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Images in  letter  category is  2110\n",
      "No of Images in  form  category is  2103\n",
      "No of Images in  email  category is  2080\n",
      "No of Images in  handwritten  category is  2105\n",
      "No of Images in  advertisement  category is  2081\n",
      "No of Images in  scientific report  category is  2113\n",
      "No of Images in  scientific publication  category is  2068\n",
      "No of Images in  specification  category is  2061\n",
      "No of Images in  file folder  category is  2064\n",
      "No of Images in  news article  category is  2062\n",
      "No of Images in  budget  category is  2116\n",
      "No of Images in  invoice  category is  2134\n",
      "No of Images in  presentation  category is  2066\n",
      "No of Images in  questionnaire  category is  2170\n",
      "No of Images in  resume  category is  2130\n",
      "No of Images in  memo  category is  2137\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"training_data\"\n",
    "os.listdir(dir_path)\n",
    "for i in os.listdir(dir_path):\n",
    "    print(\"No of Images in \",i,\" category is \",len(os.listdir(os.path.join(dir_path,i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CyRG3BdABnZq"
   },
   "outputs": [],
   "source": [
    "##Getting size of images\n",
    "list_of_heights = []\n",
    "list_of_widths = []\n",
    "for i in os.listdir(dir_path):\n",
    "    for image in os.listdir(os.path.join(dir_path,i)):\n",
    "        img = cv2.imread(os.path.join(os.path.join(dir_path,i),image), cv2.IMREAD_UNCHANGED)\n",
    "        # get dimensions of image\n",
    "        shape = img.shape\n",
    "        list_of_heights.append(shape[0])\n",
    "        list_of_widths.append(shape[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHMVq-VgX81f",
    "outputId": "cda35061-0449-45a4-da0a-772725fddd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1000]\n"
     ]
    }
   ],
   "source": [
    "print(len(list(set(list_of_heights))))\n",
    "print(list(set(list_of_heights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "G-T68zqJGsYC",
    "outputId": "370fcfeb-1d0a-4e1d-dec9-4f9ed45e8656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 900.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list_of_widths,bins=20)\n",
    "plt.hist(list_of_widths)\n",
    "plt.title('widths')\n",
    "plt.xlim(0,900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSJCSde7GuxD",
    "outputId": "92e39189-6488-4fdf-8cc7-0b19ad6c103d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list_of_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYgiDl_AGxka",
    "outputId": "e45383af-6094-4168-8427-48dcfa455ae9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_of_heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rr_kByYfGz8h",
    "outputId": "e3fa9188-5064-4920-d65c-9e6807da05bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760.0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list_of_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4TNW3fLG1xh",
    "outputId": "e79f995c-be4b-45d0-b2b1-3d59ab08b7b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766.1904867649671"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list_of_widths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14LurjUe4lvU"
   },
   "source": [
    "## MODEL-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RcfoaYDHBal-",
    "outputId": "b13ff84a-b5a8-4bcd-978a-64593da5be87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22516 images belonging to 16 classes.\n",
      "Found 10080 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/content/drive/Shareddrives/HK ROBOT/VGG16_DATA/data/training_data',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/content/drive/Shareddrives/HK ROBOT/VGG16_DATA/data/validation_data',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7mk4qgAWB6D",
    "outputId": "6c168036-6dcb-4e42-8dc7-bcc0c82ebdc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 5, 5, 550)         2534950   \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2, 2, 550)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 300)         1485300   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 300)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 19,127,554\n",
      "Trainable params: 4,412,866\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg16_model = applications.vgg16.VGG16(weights='imagenet')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:19]:\n",
    "  model.add(layer)\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='valid',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=600,activation='relu'))\n",
    "model.add(Dense(units=64,activation='relu'))\n",
    "model.add(Dense(units=32,activation='relu'))\n",
    "model.add(Dense(16, activation='softmax'))   \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "for layer in model.layers[:18]:\n",
    "  layer.trainable = False  \n",
    "\n",
    "\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtZhSigva2vx",
    "outputId": "b6c4b333-9e5c-491c-cf93-65476aad5047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "Epoch 1/6\n",
      "1050/1050 [==============================] - 605s 576ms/step - loss: 1.3929 - accuracy: 0.5785 - val_loss: 1.3277 - val_accuracy: 0.5971\n",
      "Epoch 2/6\n",
      "1050/1050 [==============================] - 582s 554ms/step - loss: 1.3406 - accuracy: 0.5931 - val_loss: 1.3138 - val_accuracy: 0.6020\n",
      "Epoch 3/6\n",
      "1050/1050 [==============================] - 551s 524ms/step - loss: 1.2955 - accuracy: 0.6111 - val_loss: 1.2662 - val_accuracy: 0.6169\n",
      "Epoch 4/6\n",
      "1050/1050 [==============================] - 547s 521ms/step - loss: 1.2740 - accuracy: 0.6138 - val_loss: 1.2281 - val_accuracy: 0.6305\n",
      "Epoch 5/6\n",
      "1050/1050 [==============================] - 562s 535ms/step - loss: 1.2393 - accuracy: 0.6262 - val_loss: 1.2266 - val_accuracy: 0.6291\n",
      "Epoch 6/6\n",
      "1050/1050 [==============================] - 569s 542ms/step - loss: 1.2266 - accuracy: 0.6263 - val_loss: 1.2072 - val_accuracy: 0.6369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f54fb208f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "log_dir=\"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, \n",
    "                                                      write_graph=True,write_grads=True)\n",
    "\n",
    "\n",
    "callback_list = [tensorboard_callback]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(train_generator,steps_per_epoch=1050,epochs=6,validation_data=validation_generator,\n",
    "          validation_steps=450,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL :- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9CMbqVYdDHq",
    "outputId": "962976e5-f48e-4ce8-f91a-841dcf22bb4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 600)               2458200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 136,930,760\n",
      "Trainable params: 122,216,072\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg16_model = applications.vgg16.VGG16(weights='imagenet')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:19]:\n",
    "  model.add(layer)\n",
    "\n",
    "model.add(Conv2D(filters=4096,kernel_size=(7,7),activation='relu'))\n",
    "model.add(Conv2D(filters=4096,kernel_size=(1,1),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='softmax'))   \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "for layer in model.layers[:18]:\n",
    "  layer.trainable = False  \n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01),loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTct5AxQz1sI",
    "outputId": "8b2f4cf6-40ca-446f-9de9-f4ad37b061db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "Epoch 1/6\n",
      "1050/1050 [==============================] - 563s 535ms/step - loss: 1.7282 - accuracy: 0.4643 - val_loss: 1.2188 - val_accuracy: 0.6234\n",
      "Epoch 2/6\n",
      "1050/1050 [==============================] - 542s 516ms/step - loss: 1.1905 - accuracy: 0.6331 - val_loss: 1.1044 - val_accuracy: 0.6651\n",
      "Epoch 3/6\n",
      "1050/1050 [==============================] - 518s 493ms/step - loss: 1.0754 - accuracy: 0.6631 - val_loss: 1.0019 - val_accuracy: 0.6916\n",
      "Epoch 4/6\n",
      "1050/1050 [==============================] - 543s 518ms/step - loss: 0.9802 - accuracy: 0.6948 - val_loss: 0.9553 - val_accuracy: 0.7084\n",
      "Epoch 5/6\n",
      "1050/1050 [==============================] - 530s 504ms/step - loss: 0.9220 - accuracy: 0.7149 - val_loss: 0.9582 - val_accuracy: 0.7103\n",
      "Epoch 6/6\n",
      "1050/1050 [==============================] - 524s 499ms/step - loss: 0.8647 - accuracy: 0.7344 - val_loss: 0.8960 - val_accuracy: 0.7286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f52c222a208>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.compile(optimizer=optimizer ,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "log_dir=\"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
    "\n",
    "\n",
    "callback_list = [tensorboard_callback]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(train_generator,steps_per_epoch=1050,epochs=6,validation_data=validation_generator,\n",
    "          validation_steps=450,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL:- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYFEKeYUrXo7",
    "outputId": "2743e36f-6af1-4fc3-960f-118ceae455fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 4s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 600)               2458200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 136,930,760\n",
      "Trainable params: 131,655,304\n",
      "Non-trainable params: 5,275,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vgg16_model = applications.vgg16.VGG16(weights='imagenet')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:19]:\n",
    "  model.add(layer)\n",
    "\n",
    "model.add(Conv2D(filters=4096,kernel_size=(7,7),activation='relu'))\n",
    "model.add(Conv2D(filters=4096,kernel_size=(1,1),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='softmax'))   \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "for layer in model.layers[:12]:\n",
    "  layer.trainable = False  \n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2X1cQyJ72V1",
    "outputId": "32214bc2-956e-464e-d0c3-141cfe73b01d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
      "Epoch 1/3\n",
      "704/704 [==============================] - 9882s 14s/step - loss: 1.4637 - accuracy: 0.5449 - val_loss: 1.1389 - val_accuracy: 0.6516\n",
      "Epoch 2/3\n",
      "704/704 [==============================] - 4348s 6s/step - loss: 1.0526 - accuracy: 0.6779 - val_loss: 0.9842 - val_accuracy: 0.7038\n",
      "Epoch 3/3\n",
      "704/704 [==============================] - 4196s 6s/step - loss: 0.8747 - accuracy: 0.7303 - val_loss: 0.8779 - val_accuracy: 0.7394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f14177e3ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "log_dir=\"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, \n",
    "                                                      write_graph=True,write_grads=True)\n",
    "\n",
    "\n",
    "callback_list = [tensorboard_callback]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(train_generator,steps_per_epoch=704,epochs=3,validation_data=validation_generator,\n",
    "          validation_steps=315,callbacks=callback_list)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlow with GPU",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
