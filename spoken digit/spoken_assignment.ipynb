{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "digit_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfYSR1tKkToL",
        "outputId": "cb2d2c57-dbc7-4221-8023-85ead0ac31bf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('content')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw9_g2EgkkhW",
        "outputId": "193ecf2b-d88d-4584-9fa2-b6283193693e"
      },
      "source": [
        "cd /content/content/MyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/content/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCHW6s5rkoCN",
        "outputId": "b3c22724-c863-4b74-ded9-60777ccc52d4"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/   recordingss.zip                         \u001b[01;34mweight_cifer\u001b[0m/\n",
            " \u001b[01;34mlstm\u001b[0m/               \u001b[01;34mspoken_digit\u001b[0m/\n",
            " \u001b[01;34mrecordings\u001b[0m/         spoken_digit-20210126T005131Z-001.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwoTWIysaNmc"
      },
      "source": [
        "<pre><font size=6>Spoken Digit Recognition</font></pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPO3mjDDaNmf"
      },
      "source": [
        "<pre>\n",
        "In this notebook, You will do Spoken Digit Recognition. \n",
        "\n",
        "Input - speech signal, output - digit number\n",
        "\n",
        "\n",
        "\n",
        "It contains  \n",
        "\n",
        "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
        "2. Training the LSTM with RAW data\n",
        "3. Converting to spectrogram and Training the LSTM network\n",
        "4. Creating the augmented data and doing step 2 and 3 again.  \n",
        "\n",
        "<font size=5>instructions:</font>\n",
        "\n",
        "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. If you manipulate any, it will be considered as plagiarised. \n",
        "    \n",
        "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
        "    \n",
        "    3. please return outputs in the same format what we asked. Eg. Don't return List of we are asking for a numpy array.\n",
        "    \n",
        "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
        "    \n",
        "    5. We are giving instructions at each section if necessary, please follow them. \n",
        "\n",
        "<font size=5>Every Grader function has to return True. </font>\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qGuPcj-aNmh"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "##if you need any imports you can do that here. "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWWxhKPId8a8"
      },
      "source": [
        "all_files = list()\n",
        "data_files = os.listdir('recordings')\n",
        "for i,sub_file in enumerate(data_files):\n",
        "  if (sub_file.endswith(\"wav\")):\n",
        "    sub_file_path = 'recordings' + '/' + sub_file\n",
        "    sub_file_path = str(sub_file_path)\n",
        "    all_files.append(sub_file_path)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NYYpfqoaNmv"
      },
      "source": [
        "<font size=4>Grader function 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oJSOmYBaNmx",
        "outputId": "490d96eb-6d54-4818-e027-8c52ec9dc776"
      },
      "source": [
        "def grader_files():\n",
        "    temp = len(all_files)==2000\n",
        "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
        "    temp = temp and temp1\n",
        "    return temp\n",
        "grader_files()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhvSIN6raNm3"
      },
      "source": [
        "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
        "You can get the label from the first letter of name.  \n",
        "Eg: 0_jackson_0 --> 0  \n",
        "0_jackson_43 --> 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "fWP6vXBeaNm3",
        "outputId": "2025c2ba-af63-4e71-bef6-0fa7a94b2bf3"
      },
      "source": [
        "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
        "#You can get the label from the first letter of name.  \n",
        "#Eg: 0_jackson_0 --> 0  \n",
        "#0_jackson_43 --> 0\n",
        "label = [int(x[11]) for x in all_files]\n",
        "label[0:5]\n",
        "\n",
        "# intialise data of lists. \n",
        "data = {'path':all_files, \n",
        "        'label':label} \n",
        "  \n",
        "# Create DataFrame \n",
        "df_audio = pd.DataFrame(data) \n",
        "df_audio.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recordings/7_nicolas_39.wav</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recordings/9_nicolas_32.wav</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recordings/8_theo_9.wav</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recordings/7_theo_20.wav</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recordings/0_nicolas_8.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          path  label\n",
              "0  recordings/7_nicolas_39.wav      7\n",
              "1  recordings/9_nicolas_32.wav      9\n",
              "2      recordings/8_theo_9.wav      8\n",
              "3     recordings/7_theo_20.wav      7\n",
              "4   recordings/0_nicolas_8.wav      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWFdClepbkAO"
      },
      "source": [
        "y = df_audio['label'].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x29Zt7MhUzN",
        "outputId": "9f4a6803-f00e-4387-fdef-6785e2a463ef"
      },
      "source": [
        "#info\n",
        "df_audio.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   path    2000 non-null   object\n",
            " 1   label   2000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 31.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOKpYJ_LaNnD"
      },
      "source": [
        "<font size=4>Grader function 2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q8r_T8-aNnE",
        "outputId": "377744c7-b07a-455d-dd21-1f02d010d235"
      },
      "source": [
        "def grader_df():\n",
        "    #flag_shape = df_audio.shape==(2000,2)\n",
        "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
        "    list_values = list(df_audio.label.value_counts())\n",
        "    flag_label = len(list_values)==10\n",
        "    flag_label2 = all([i==200 for i in list_values])\n",
        "    final_flag = flag_columns and flag_columns and flag_label and flag_label2\n",
        "    return final_flag\n",
        "grader_df()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlfssCc3aNnL"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ448aENaNnR"
      },
      "source": [
        "<pre><font size=4>Train and Validation split</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSPy-Ln6aNnS"
      },
      "source": [
        "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
        "#use stratify sampling\n",
        "#use random state of 45\n",
        "#use test size of 30%\n",
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_audio['path'],df_audio['label'] , test_size=0.3, stratify=df_audio['label'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPK3sbzUaNnW"
      },
      "source": [
        "<font size=4>Grader function 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chZzntKUaNnX",
        "outputId": "a4292590-6e72-4361-9320-d515c57e4e96"
      },
      "source": [
        "def grader_split():\n",
        "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
        "    values_ytrain = list(y_train.value_counts())\n",
        "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
        "    values_ytest = list(y_test.value_counts())\n",
        "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
        "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
        "    return final_flag\n",
        "grader_split()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGhh-39vaNnb"
      },
      "source": [
        "<pre><font size=4>Preprocessing</font>\n",
        "\n",
        "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99JacQSaNnc"
      },
      "source": [
        "sample_rate = 22050\n",
        "def load_wav(x, get_duration=True):\n",
        "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
        "    #loading the wav file with sampling rate of 22050\n",
        "    samples, sample_rate = librosa.load(x, sr=22050)\n",
        "    if get_duration:\n",
        "        duration = librosa.get_duration(samples, sample_rate)\n",
        "        return [samples, duration]\n",
        "    else:\n",
        "        return samples"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnjnmhpfm_Up"
      },
      "source": [
        "X_train_process = [load_wav(row, get_duration=True) for row in X_train.tolist()]\n",
        "X_test_process = [load_wav(row, get_duration=True) for row in X_test.tolist()]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx97f8GGaNnh"
      },
      "source": [
        "#use load_wav function that was written above to get every wave. \n",
        "#save it in X_train_processed and X_test_processed\n",
        "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1y4c66rSsFGF",
        "outputId": "ec8bbeb7-e283-4de6-bf85-09172f3c395b"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "#plot the histogram of the duration for trian\n",
        "\n",
        "X_train_duration  = [i[1] for i in X_train_process]\n",
        "# plot scores\n",
        "pyplot.hist(X_train_duration)\n",
        "pyplot.title(\"Histogram of X_train_duration\")\n",
        "pyplot.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWjElEQVR4nO3df7RdZX3n8fdHAv4CCUgamSQYLKkdXGtEmsE4aoeRdhZgNcyqZWFbCUyczKrU0VGnpozjj1a7sKujwjiLaQpKUKsyVCWj1JaFsqwzhRoUUUCHiDBJBHJFCCL+KPU7f+zn0pPr/XFucu89yc77tdZZ59nPfs7ez97n3M/Z5zn77JuqQpLUL08YdQckSXPPcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3HsuyW1JTh11P0Ypyb9Jsj3JI0meN+r+DEpyYZLL5niZpybZMZfLHGKdjyR51kKuU9Mz3A9gSe5O8isT6s5L8sXx6ap6TlXdMMNyViapJIvmqauj9ifA71bV4VX1lcEZSZYleTDJiwbqVrS650+30CQ3JHn1vnSsqv6oqvZpGQttsu1u+/auUfVJP8tw17zbD940ngncNtmMqtoJvBm4LMmTWvWfAh+sqpv2ZaX7wXbP2oHYZ03OcO+5waP7JKck2Zrk4ST3J3lPa/aFdv9Q+3j9giRPSPKWJPck2ZXkyiRHDiz33DbvgST/ZcJ63p7k6iQfTvIwcF5b998meSjJvUnen+SwgeVVktckuTPJ95P8YZKfT/J/Wn+vGmw/YRsn7WuSJyZ5BDgE+GqSb02xm/4MuBd4W5J1wLOBt8ywX98FvBh4f9tn7x/YjguS3Anc2eoubsNCDye5OcmLB5bz9iQfbuXxT1Drkvy/JN9N8p+n60d73JOTXNE+bdwO/PMJ8yvJCQPTVyR5ZyufmmRHkjcnuQ/4YJKjknw6yVhb5qeTLB9iu09o5SPbczDWnpO3JHlCm3deki8m+ZO27G8nOWOmbdReqCpvB+gNuBv4lQl15wFfnKwN8LfAq1r5cGBNK68EClg08Lh/C2wDntXafgL4UJt3IvAI8CLgMLphj78fWM/b2/RZdAcQTwZ+CVgDLGrruwN4/cD6CrgGeBrwHODHwPVt/UcCtwPrptgPU/Z1YNknzLAvfx7YDTwIvGTI/X8D8OoJdQVcBxwNPLnV/Tbw9LbtbwTuA540sK8+POF5+LO2z57b9sM/naEfFwF/09a5Avg6sGOq7QeuAN7ZyqcCjwHvBp7Y1vt04NeBpwBHAP8T+NQQ231CK1/Znssj2jb9X2D9wOvz74F/R/em+zvAd4CM+u+pb7eRd8DbPjx5XXA/Ajw0cHuUqcP9C8A7gGMmLGc8VAbD/XrgNQPTz25/lIuAtwIfHZj3FOAn7BnuX5ih768HPjkwXcALB6ZvBt48MP1fgfdNsawp+zqw7JnCfRHdG849g/thhsdMFXLTvjnQvYE8d2BfTQz35QNt/w44Z4bl3QWcPjC9gdmF+09obzZTLP8k4MEhtvuEFtg/AU4cmPfvgRta+Txg24TXTgHPGPXfU99uDssc+M6qqsXjN+A107RdD/wC8I0kX0rya9O0/Sd0QTfuHroAXNrmbR+fUVWPAg9MePz2wYkkv9A+3t/Xhmr+CDhmwmPuHyj/cJLpw/eir8PaSLcNu4A3zeJxk5m47W9KckeS3UkeovskMnHbB903UH6Uqbd73B7PB3vui2GMVdWPBvr7lCR/2oZUHqY7KFic5JAhlnUMcCg/+3wsG5h+fPvaawdm3kbNkuF+EKmqO6vqlcDP0X0MvzrJU+mOnCb6Dt0XkeOOo/v4fj/d+PTy8RlJxj/K77G6CdOXAt8AVlXV04ALgez91gzd1xklORH4T8Cr6d4AL0yyaoiHTnVJ1cfr2/j67wFnA0e1N+DdzN22Q/d8rBiYPm7C/EfpjpDHPWPC/Inb8Ua6Tz/Pb8/VL7f6TNF+0HfpPjVNfD52TvMYzQPD/SCS5LeTLKmqn9IN4QD8FBhr94PnKX8U+I9Jjk9yON2R9ser6jHgauBlSf5F+5Lz7cwcVkcADwOPJPlFurHWuTJdX6fVvui7HPjjqvpGVd0KXAJsSjLTNt3PnvtsMkfQvdGMAYuSvJXue4W5dBXw++2L0OXAayfMvwX4zSSHJDkd+JdD9PmHdF+wHw28bcL8Kbe7qv6h9eddSY5I8kzgDcCHZ7VF2meG+8HldOC2dgbJxXRjuT9sH43fBfzvdjbLGuADwIfoPpJ/G/gRLTSq6rZW/hjdUeMjdMMZP55m3W8CfhP4Pt0Xhh+fw+2asq9DeB3dUe0fD9T9Id3R7Uznn18MvKKd9XHJFG3+Cvgs3ZeK97S+bZ+i7d56R1v2t4G/ptsXg14HvIzuDf23gE/NsLz30X2x+l3gRrr+D5ppu18L/IDuu4AvAn9O9xxpAaV9qSHttXa0/BDdkMu3R90fSR65ay8leVn74u2pdKdCfo3uzBxJ+wHDXXtrLd0Xmd8BVtEN8fTuY2D7oc5ktxfP/Og57cdfTtGPCxeyHzpwOCwjST3kkbsk9dB+cZGgY445plauXDnqbkjSAeXmm2/+blUtmWzejOGe5Nnsedras+h+fn5lq19J90Xa2VX1YDs3+GLgTLofT5xXVV+ebh0rV65k69atM2+JJOlxSab8NfKMwzJV9c2qOqmqTqK7+NOjwCfpfq59fVWtoru2x8b2kDPovmBbRXeNi0v3rfuSpNma7Zj7acC3quoeurMlNrf6zXRXAKTVX1mdG+muSXHsnPRWkjSU2Yb7OXQ/9QZYWlX3tvJ9/ONFmpax5y/wdrDnRYMASLIh3bXFt46Njc2yG5Kk6Qwd7u0aIi+nu7bzHtr5zbM6p7KqNlXV6qpavWTJpN8HSJL20myO3M8AvlxV41fau398uKXd72r1O9nzCnXL8YpwkrSgZhPur+Qfh2QAtgDrWnkd3X9eGa8/N501wO6B4RtJ0gIY6jz3dv2QX6X7jyrjLgKuSrKe7op0Z7f6a+lOg9xGd2bN+XPWW0nSUIYK96r6ARP+GUNVPUB39szEtgVcMCe9kyTtFS8/IEk9tF9cfuBAtXLjZ0ay3rsveulI1ivpwOGRuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8NFe5JFie5Osk3ktyR5AVJjk5yXZI72/1RrW2SXJJkW5Jbk5w8v5sgSZpo2H+QfTHw2ap6RZLDgKcAFwLXV9VFSTYCG4E3A2cAq9rt+cCl7X5ejOqfVEvS/mzGI/ckRwK/DFwOUFU/qaqHgLXA5tZsM3BWK68FrqzOjcDiJMfOec8lSVMaZljmeGAM+GCSryS5LMlTgaVVdW9rcx+wtJWXAdsHHr+j1e0hyYYkW5NsHRsb2/stkCT9jGHCfRFwMnBpVT0P+AHdEMzjqqqAms2Kq2pTVa2uqtVLliyZzUMlSTMYJtx3ADuq6qY2fTVd2N8/PtzS7ne1+TuBFQOPX97qJEkLZMZwr6r7gO1Jnt2qTgNuB7YA61rdOuCaVt4CnNvOmlkD7B4YvpEkLYBhz5Z5LfCRdqbMXcD5dG8MVyVZD9wDnN3aXgucCWwDHm1tJUkLaKhwr6pbgNWTzDptkrYFXLCP/ZIk7QN/oSpJPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8NFe5J7k7ytSS3JNna6o5Ocl2SO9v9Ua0+SS5Jsi3JrUlOns8NkCT9rNkcuf+rqjqpqla36Y3A9VW1Cri+TQOcAaxqtw3ApXPVWUnScPZlWGYtsLmVNwNnDdRfWZ0bgcVJjt2H9UiSZmnYcC/gr5PcnGRDq1taVfe28n3A0lZeBmwfeOyOVreHJBuSbE2ydWxsbC+6LkmayqIh272oqnYm+TnguiTfGJxZVZWkZrPiqtoEbAJYvXr1rB4rSZreUEfuVbWz3e8CPgmcAtw/PtzS7ne15juBFQMPX97qJEkLZMZwT/LUJEeMl4F/DXwd2AKsa83WAde08hbg3HbWzBpg98DwjSRpAQwzLLMU+GSS8fZ/XlWfTfIl4Kok64F7gLNb+2uBM4FtwKPA+XPea0nStGYM96q6C3juJPUPAKdNUl/ABXPSO0nSXvEXqpLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDQ4d7kkOSfCXJp9v08UluSrItyceTHNbqn9imt7X5K+en65KkqczmyP11wB0D0+8G3ltVJwAPAutb/XrgwVb/3tZOkrSAhgr3JMuBlwKXtekALwGubk02A2e18to2TZt/WmsvSVogwx65vw/4PeCnbfrpwENV9Vib3gEsa+VlwHaANn93a7+HJBuSbE2ydWxsbC+7L0mazIzhnuTXgF1VdfNcrriqNlXV6qpavWTJkrlctCQd9BYN0eaFwMuTnAk8CXgacDGwOMmidnS+HNjZ2u8EVgA7kiwCjgQemPOeS5KmNOORe1X9flUtr6qVwDnA56rqt4DPA69ozdYB17TyljZNm/+5qqo57bUkaVr7cp77m4E3JNlGN6Z+eau/HHh6q38DsHHfuihJmq1hhmUeV1U3ADe08l3AKZO0+RHwG3PQN0nSXvIXqpLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9dCM4Z7kSUn+LslXk9yW5B2t/vgkNyXZluTjSQ5r9U9s09va/JXzuwmSpImGOXL/MfCSqnoucBJwepI1wLuB91bVCcCDwPrWfj3wYKt/b2snSVpAM4Z7dR5pk4e2WwEvAa5u9ZuBs1p5bZumzT8tSeasx5KkGQ015p7kkCS3ALuA64BvAQ9V1WOtyQ5gWSsvA7YDtPm7gadPsswNSbYm2To2NrZvWyFJ2sNQ4V5V/1BVJwHLgVOAX9zXFVfVpqpaXVWrlyxZsq+LkyQNmNXZMlX1EPB54AXA4iSL2qzlwM5W3gmsAGjzjwQemJPeSpKGMszZMkuSLG7lJwO/CtxBF/KvaM3WAde08pY2TZv/uaqquey0JGl6i2ZuwrHA5iSH0L0ZXFVVn05yO/CxJO8EvgJc3tpfDnwoyTbge8A589BvSdI0Zgz3qroVeN4k9XfRjb9PrP8R8Btz0jtJ0l7xF6qS1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQ4a7JPWQ4S5JPWS4S1IPGe6S1EOGuyT1kOEuST1kuEtSDxnuktRDhrsk9ZDhLkk9ZLhLUg8Z7pLUQzOGe5IVST6f5PYktyV5Xas/Osl1Se5s90e1+iS5JMm2JLcmOXm+N0KStKdhjtwfA95YVScCa4ALkpwIbASur6pVwPVtGuAMYFW7bQAunfNeS5KmNWO4V9W9VfXlVv4+cAewDFgLbG7NNgNntfJa4Mrq3AgsTnLsnPdckjSlWY25J1kJPA+4CVhaVfe2WfcBS1t5GbB94GE7Wp0kaYEMHe5JDgf+Anh9VT08OK+qCqjZrDjJhiRbk2wdGxubzUMlSTMYKtyTHEoX7B+pqk+06vvHh1va/a5WvxNYMfDw5a1uD1W1qapWV9XqJUuW7G3/JUmTGOZsmQCXA3dU1XsGZm0B1rXyOuCagfpz21kza4DdA8M3kqQFsGiINi8EXgV8Lcktre5C4CLgqiTrgXuAs9u8a4EzgW3Ao8D5c9pjSdKMZgz3qvoikClmnzZJ+wIu2Md+SZL2gb9QlaQeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWph2YM9yQfSLIrydcH6o5Ocl2SO9v9Ua0+SS5Jsi3JrUlOns/OS5ImN8yR+xXA6RPqNgLXV9Uq4Po2DXAGsKrdNgCXzk03JUmzMWO4V9UXgO9NqF4LbG7lzcBZA/VXVudGYHGSY+eqs5Kk4Szay8ctrap7W/k+YGkrLwO2D7Tb0eruZYIkG+iO7jnuuOP2shsHp5UbPzOydd990UtHtm5Jw9vnL1SrqoDai8dtqqrVVbV6yZIl+9oNSdKAvQ33+8eHW9r9rla/E1gx0G55q5MkLaC9DfctwLpWXgdcM1B/bjtrZg2we2D4RpK0QGYcc0/yUeBU4JgkO4C3ARcBVyVZD9wDnN2aXwucCWwDHgXOn4c+S5JmMGO4V9Urp5h12iRtC7hgXzslSdo3/kJVknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeMtwlqYcMd0nqIcNdknrIcJekHjLcJamHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seshwl6QeWjQfC01yOnAxcAhwWVVdNB/r0cJbufEzI1nv3Re9dCTrlQ5Uc37knuQQ4L8DZwAnAq9McuJcr0eSNLX5OHI/BdhWVXcBJPkYsBa4fR7WpYOEnxg0n0b1+oL5e43NR7gvA7YPTO8Anj+xUZINwIY2+UiSb85DXw4UxwDfHXUn9mMj2z959yjWOiu+dqa33++ffXyNPXOqGfMy5j6MqtoEbBrV+vcnSbZW1epR92N/5f6Zmvtmegfz/pmPs2V2AisGppe3OknSApmPcP8SsCrJ8UkOA84BtszDeiRJU5jzYZmqeizJ7wJ/RXcq5Aeq6ra5Xk/PODw1PffP1Nw30zto90+qatR9kCTNMX+hKkk9ZLhLUg8Z7gsoyelJvplkW5KNk8w/L8lYklva7dWj6OcoJPlAkl1Jvj7F/CS5pO27W5OcvNB9HJUh9s2pSXYPvG7eutB9HKUkK5J8PsntSW5L8rpJ2hx0rx/DfYHM4rIMH6+qk9rtsgXt5GhdAZw+zfwzgFXttgG4dAH6tL+4gun3DcDfDLxu/mAB+rQ/eQx4Y1WdCKwBLpjkb+uge/0Y7gvn8csyVNVPgPHLMgioqi8A35umyVrgyurcCCxOcuzC9G60htg3B7WqureqvtzK3wfuoPul/KCD7vVjuC+cyS7LMPEFCPDr7WPj1UlWTDL/YDXs/jtYvSDJV5P8ZZLnjLozo5JkJfA84KYJsw6614/hvn/5X8DKqvpnwHXA5hH3RweGLwPPrKrnAv8N+NSI+zMSSQ4H/gJ4fVU9POr+jJrhvnBmvCxDVT1QVT9uk5cBv7RAfTsQeFmLKVTVw1X1SCtfCxya5JgRd2tBJTmULtg/UlWfmKTJQff6MdwXzoyXZZgwBvhyurFDdbYA57azHtYAu6vq3lF3an+Q5BlJ0sqn0P1dPzDaXi2ctu2XA3dU1XumaHbQvX5GdlXIg81Ul2VI8gfA1qraAvyHJC+n+/b/e8B5I+vwAkvyUeBU4JgkO4C3AYcCVNX/AK4FzgS2AY8C54+mpwtviH3zCuB3kjwG/BA4pw6un56/EHgV8LUkt7S6C4Hj4OB9/Xj5AUnqIYdlJKmHDHdJ6iHDXZJ6yHCXpB4y3CWphwx3Seohw12Seuj/A8fLg/USEBQ8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE5SDRzSaNns"
      },
      "source": [
        "#print 0 to 100 percentile values with step size of 10 for train data duration. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcmUeIIYut9s",
        "outputId": "bebfa9a3-4588-4948-8d6c-c6d69747912f"
      },
      "source": [
        "import numpy as np\n",
        "p = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "range =  np.percentile(X_train_duration, p)\n",
        "\n",
        "for i , j  in enumerate(range):\n",
        "  print(f'{p[i]} th percentile is {range[i]}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 th percentile is 0.1435374149659864\n",
            "10 th percentile is 0.25988208616780045\n",
            "20 th percentile is 0.30080725623582766\n",
            "30 th percentile is 0.33424489795918366\n",
            "40 th percentile is 0.36007256235827667\n",
            "50 th percentile is 0.3915873015873016\n",
            "60 th percentile is 0.418639455782313\n",
            "70 th percentile is 0.44988662131519275\n",
            "80 th percentile is 0.48596825396825394\n",
            "90 th percentile is 0.5549160997732426\n",
            "100 th percentile is 2.282766439909297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvLhm1AqaNny"
      },
      "source": [
        "##print 90 to 100 percentile values with step size of 1. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxbtzvJizVoR",
        "outputId": "c6cdc18c-1ac6-4c20-93fb-aaebca28139e"
      },
      "source": [
        "import numpy as np\n",
        "p = [90,91,92,93,94,95,96,97,98,99,100]\n",
        "range =  np.percentile(X_train_duration, p)\n",
        "\n",
        "for i , j  in enumerate(range):\n",
        "  print(f'{p[i]} th percentile is {range[i]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90 th percentile is 0.5549160997732426\n",
            "91 th percentile is 0.5659854875283448\n",
            "92 th percentile is 0.5779083900226759\n",
            "93 th percentile is 0.5933292517006803\n",
            "94 th percentile is 0.609092970521542\n",
            "95 th percentile is 0.6231496598639454\n",
            "96 th percentile is 0.6420553287981859\n",
            "97 th percentile is 0.6635741496598639\n",
            "98 th percentile is 0.6956090702947844\n",
            "99 th percentile is 0.7831392290249433\n",
            "100 th percentile is 2.282766439909297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0J6mN6qsXpJ"
      },
      "source": [
        "X_trian_raw_data = [i[0] for i in X_train_process]\n",
        "X_train_duration = [i[1] for i in X_train_process]\n",
        "\n",
        "dict = {'raw_data':X_trian_raw_data , 'duration':X_train_duration}\n",
        "\n",
        "X_train_processed = pd.DataFrame(dict)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_AI6yPhs4GM"
      },
      "source": [
        "X_test_raw_data = [i[0] for i in X_test_process]\n",
        "X_test_duration = [i[1] for i in X_test_process]\n",
        "\n",
        "dict = {'raw_data':X_test_raw_data , 'duration':X_test_duration}\n",
        "\n",
        "X_test_processed = pd.DataFrame(dict)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMb4Y0RaNoA"
      },
      "source": [
        "<font size=4>Grader function 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMoyLLSAaNoF",
        "outputId": "ebd9ec4f-7509-4f9a-8786-95ad4950eee7"
      },
      "source": [
        "def grader_processed():\n",
        "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
        "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
        "    return flag_columns and flag_shape\n",
        "grader_processed()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cux3_jfcaNoM"
      },
      "source": [
        "<pre>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset. \n",
        "\n",
        "While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
        "\n",
        "Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
        "\n",
        "Also create a masking vector for train and test. \n",
        "\n",
        "masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2n3NLkD7HB3"
      },
      "source": [
        "X_train_sample = [i[0] for i in X_train_processed]\n",
        "X_test_sample = [i[0] for i in X_test_processed]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voqSEyvcaNoO"
      },
      "source": [
        "max_length  = 17640"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1-_r20BaNoW"
      },
      "source": [
        "## as discussed above, Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
        "## save in the X_train_pad_seq, X_test_pad_seq\n",
        "## also Create masking vector X_train_mask, X_test_mask\n",
        "\n",
        "## all the X_train_pad_seq, X_test_pad_seq, X_train_mask, X_test_mask will be numpy arrays mask vector dtype must be bool."
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "m1YWxs1UvsdB",
        "outputId": "f0a80966-ca30-40df-8a73-fbb2468765a8"
      },
      "source": [
        "X_train_processed.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_data</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.004544994, -0.0043530054, -0.012745843, -0....</td>\n",
              "      <td>0.422404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.00025552875, 2.5027432e-05, 0.00012410665, ...</td>\n",
              "      <td>0.391882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.00746698, -0.0061093145, -0.0028450494, 0....</td>\n",
              "      <td>0.374785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.013037005, -0.009333977, 0.0036948763, 0.0...</td>\n",
              "      <td>0.469887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.0003973734, -0.00043307224, -0.00045968636...</td>\n",
              "      <td>0.318005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            raw_data  duration\n",
              "0  [0.004544994, -0.0043530054, -0.012745843, -0....  0.422404\n",
              "1  [0.00025552875, 2.5027432e-05, 0.00012410665, ...  0.391882\n",
              "2  [-0.00746698, -0.0061093145, -0.0028450494, 0....  0.374785\n",
              "3  [-0.013037005, -0.009333977, 0.0036948763, 0.0...  0.469887\n",
              "4  [-0.0003973734, -0.00043307224, -0.00045968636...  0.318005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1xDVDk2vytL"
      },
      "source": [
        "X_train_sample = X_train_processed['raw_data'].values\n",
        "X_test_sample = X_test_processed['raw_data'].values"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNkafjruzDn0",
        "outputId": "da3a62cf-e01c-4427-b867-e7ee109dda1f"
      },
      "source": [
        "X_train_sample.shape,X_test_sample.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400,), (600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPFrrT69scVb"
      },
      "source": [
        "X_train_pad_seq = []\n",
        "for li in X_train_sample:\n",
        "  if len(li) < max_length:\n",
        "    li = li.tolist()\n",
        "    a = [0]*(max_length - len(li))\n",
        "    li.extend(a)\n",
        "    X_train_pad_seq.append(li)\n",
        "\n",
        "  else:\n",
        "    li = li.tolist()\n",
        "    X_train_pad_seq.append(li[0:max_length])\n",
        "\n",
        "X_train_pad_seq = np.array(X_train_pad_seq)\n",
        "\n",
        "\n",
        "X_test_pad_seq = []\n",
        "for li in X_test_sample:\n",
        "  if len(li) < max_length:\n",
        "    li = li.tolist()\n",
        "    a = [0]*(max_length - len(li))\n",
        "    li.extend(a)\n",
        "    X_test_pad_seq.append(li)\n",
        "\n",
        "  else:\n",
        "    li = li.tolist()\n",
        "    X_test_pad_seq.append(li[0:max_length])\n",
        "\n",
        "X_test_pad_seq = np.array(X_test_pad_seq)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlW9qaqK35I_"
      },
      "source": [
        "X_train_mask = np.array([(i > 0).tolist()for i in X_train_pad_seq])\n",
        "X_test_mask = np.array([(i > 0).tolist()for i in X_test_pad_seq])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9ypbkyX39LW",
        "outputId": "4bca3c1a-2bf5-4db8-fc96-036d38b39fd9"
      },
      "source": [
        "X_train_mask.dtype , X_test_mask.dtype"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('bool'), dtype('bool'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEHMgm4DaNoe"
      },
      "source": [
        "<font size=4>Grader function 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th3KhplGaNof",
        "outputId": "c41e733a-607f-4a8d-c9f9-2742e97292b0"
      },
      "source": [
        "def grader_padoutput():\n",
        "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
        "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
        "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
        "    return flag_padshape and flag_maskshape and flag_dtype\n",
        "    return flag_padshape\n",
        "grader_padoutput()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r_9u9iuFUHj"
      },
      "source": [
        "X_train_mask = X_train_mask.astype('float')\n",
        "X_test_mask = X_test_mask.astype('float')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0kaYQ1jaNop"
      },
      "source": [
        "### 1. Giving Raw data directly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGHxh3jTaNoq"
      },
      "source": [
        "<pre>\n",
        "Now we have\n",
        "\n",
        "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
        "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
        "\n",
        "We will create a LSTM model which takes this input. \n",
        "\n",
        "Task:\n",
        "\n",
        "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
        "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). \n",
        "3. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
        "4. make sure that it won't overfit. \n",
        "5. You are free to include any regularization\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFu0h07LVpHJ",
        "outputId": "3645b69d-45c8-415d-ee96-100ff5b08db8"
      },
      "source": [
        "X_train_pad_seq.shape[1]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfSABmtKAqfV"
      },
      "source": [
        "Y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cyg6p4g6ikn"
      },
      "source": [
        "##MODEL :- 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8y1sgeVaNoy",
        "outputId": "a227dd8e-8fcd-4749-dfb8-6d066aed2ea2"
      },
      "source": [
        "## as discussed above, please write the LSTM\n",
        "\n",
        "lstm = LSTM(units = 25,activation=\"tanh\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0))\n",
        "\n",
        "input_layer = Input(shape=(X_train_pad_seq.shape[1],1),dtype=float )\n",
        "input_mask = Input(shape=(X_train_mask.shape[1],1),dtype=bool)\n",
        "LSTM_layer  = lstm(inputs=input_layer,mask=input_mask)\n",
        "dense = Dense(50,activation=\"relu\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0))(LSTM_layer)\n",
        "output_1 = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(dense)\n",
        "\n",
        "model = Model(inputs = [input_layer,input_mask],outputs = output_1)\n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.sparse_categorical_crossentropy,metrics='accuracy')\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 25)           2700        input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           1300        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           510         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,510\n",
            "Trainable params: 4,510\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eePuX7ePV1b9"
      },
      "source": [
        "class f1_score_and_auc_Callback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def  on_train_begin(self,logs={}):\n",
        "      self.f1_micro=[]\n",
        "      self.auc_score=[]\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      y_pred=self.model.predict([X_test_pad_seq,X_test_mask])\n",
        "      y_pred = np.argmax(y_pred, axis = 1)\n",
        "\n",
        "      y_true=y_test\n",
        "      score=f1_score(y_true, y_pred, average='micro')\n",
        "\n",
        "      self.f1_micro.append(score)\n",
        "      print(\" F1 micro :\",score)\n",
        "\n",
        "metrics=f1_score_and_auc_Callback()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klpl4vsz6wId",
        "outputId": "f1ce091e-7a2e-45a8-cad1-abfdbc8062e2"
      },
      "source": [
        "model.fit(x=[X_train_pad_seq,X_train_mask],y=y_train,validation_data=([X_test_pad_seq,X_test_mask],y_test),\n",
        "            epochs=5,batch_size=10,steps_per_epoch=len(X_train_mask)//10 , callbacks=metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "140/140 [==============================] - 63s 227ms/step - loss: 2.3092 - accuracy: 0.1023 - val_loss: 2.3015 - val_accuracy: 0.0917\n",
            " F1 micro : 0.10499999999999998\n",
            "Epoch 2/5\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 2.2991 - accuracy: 0.0888 - val_loss: 2.2991 - val_accuracy: 0.1400\n",
            " F1 micro : 0.115\n",
            "Epoch 3/5\n",
            "140/140 [==============================] - 31s 218ms/step - loss: 2.2981 - accuracy: 0.1119 - val_loss: 2.2984 - val_accuracy: 0.1100\n",
            " F1 micro : 0.095\n",
            "Epoch 4/5\n",
            "140/140 [==============================] - 30s 217ms/step - loss: 2.2939 - accuracy: 0.1097 - val_loss: 2.2948 - val_accuracy: 0.1317\n",
            " F1 micro : 0.10333333333333333\n",
            "Epoch 5/5\n",
            "140/140 [==============================] - 30s 218ms/step - loss: 2.2918 - accuracy: 0.1166 - val_loss: 2.2915 - val_accuracy: 0.1250\n",
            " F1 micro : 0.09333333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa4f57bf7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fwk0X4zaNpR"
      },
      "source": [
        "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
        "<pre>\n",
        "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
        "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb5AGzTjaNpS"
      },
      "source": [
        "def convert_to_spectrogram(raw_data):\n",
        "    '''converting to spectrogram'''\n",
        "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=sample_rate, n_mels=64)\n",
        "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
        "    return logmel_spectrum"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7C0Eha9xWbH"
      },
      "source": [
        "X_train_spectrogram = [convert_to_spectrogram(row) for row in X_train_pad_seq]\n",
        "X_train_spectrogram = np.array(X_train_spectrogram)\n",
        "\n",
        "X_test_spectrogram = [convert_to_spectrogram(row) for row in X_test_pad_seq]\n",
        "X_test_spectrogram = np.array(X_test_spectrogram)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B__rN4RjaNpc"
      },
      "source": [
        "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
        "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr1ynYZnaNpj"
      },
      "source": [
        "<font size=4>Grader function 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oniXBXcsaNpk",
        "outputId": "bcb4c897-2a94-44d8-fcfc-704228caf02f"
      },
      "source": [
        "def grader_spectrogram():\n",
        "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
        "    return flag_shape\n",
        "grader_spectrogram()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ4XYjwVtHD9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_JTShHIGu6W"
      },
      "source": [
        "##MODEL :- 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A4YzHFNtIGF"
      },
      "source": [
        "class f1_score_and_auc_Callback(tf.keras.callbacks.Callback):\r\n",
        "\r\n",
        "    def  on_train_begin(self,logs={}):\r\n",
        "      self.f1_micro=[]\r\n",
        "      self.auc_score=[]\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "      y_pred=self.model.predict(X_test_spectrogram)\r\n",
        "      y_pred = np.argmax(y_pred, axis = 1)\r\n",
        "\r\n",
        "      y_true=y_test\r\n",
        "      score=f1_score(y_true, y_pred, average='micro')\r\n",
        "  \r\n",
        "\r\n",
        "      self.f1_micro.append(score)\r\n",
        "      print(\" F1 micro :\",score)\r\n",
        "    \r\n",
        "\r\n",
        "metrics1=f1_score_and_auc_Callback()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-SPeSmr01io",
        "outputId": "a4ea6395-b95d-4666-a9be-cf2710703c43"
      },
      "source": [
        "## as discussed above, please write the LSTM\n",
        "\n",
        "lstm = LSTM(units = 100,activation=\"tanh\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0),return_sequences=True)\n",
        "\n",
        "input_layer = Input(shape=(X_test_spectrogram[0].shape),dtype=float)\n",
        "LSTM_layer  = lstm(inputs=input_layer)\n",
        "glo_avg = tf.keras.layers.GlobalAveragePooling1D(data_format='channels_first')(LSTM_layer)\n",
        "dense = Dense(50,activation=\"relu\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0))(glo_avg)\n",
        "output_1 = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(dense)\n",
        "\n",
        "model = Model(inputs = [input_layer],outputs = output_1)\n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.sparse_categorical_crossentropy,metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 64, 35)]          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64, 100)           54400     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                3250      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 58,160\n",
            "Trainable params: 58,160\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfJdiXfX-0uv",
        "outputId": "57ca69f6-ed7b-4cbe-cca7-fdf35e998797"
      },
      "source": [
        "X_train_spectrogram.shape , X_test_spectrogram.shape ,y_train.shape,y_test.shape\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1400, 64, 35), (600, 64, 35), (1400,), (600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEMMtMM1tAgX",
        "outputId": "44f00a30-5e02-4714-f95a-b770538670cf"
      },
      "source": [
        "model.fit(x=X_train_spectrogram,y=y_train,validation_data=(X_test_spectrogram,y_test),\r\n",
        "            epochs=60,batch_size=10,steps_per_epoch=len(X_train_spectrogram)//10, callbacks=metrics1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 2.0538 - accuracy: 0.2607 - val_loss: 1.8639 - val_accuracy: 0.3667\n",
            " F1 micro : 0.36666666666666664\n",
            "Epoch 2/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 1.6948 - accuracy: 0.4371 - val_loss: 1.5437 - val_accuracy: 0.4650\n",
            " F1 micro : 0.465\n",
            "Epoch 3/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 1.4344 - accuracy: 0.5150 - val_loss: 1.4146 - val_accuracy: 0.5200\n",
            " F1 micro : 0.52\n",
            "Epoch 4/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 1.2568 - accuracy: 0.6050 - val_loss: 1.1972 - val_accuracy: 0.6400\n",
            " F1 micro : 0.64\n",
            "Epoch 5/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 1.1125 - accuracy: 0.6621 - val_loss: 1.0655 - val_accuracy: 0.6500\n",
            " F1 micro : 0.65\n",
            "Epoch 6/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 1.0267 - accuracy: 0.6850 - val_loss: 0.9794 - val_accuracy: 0.7017\n",
            " F1 micro : 0.7016666666666667\n",
            "Epoch 7/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.9289 - accuracy: 0.7179 - val_loss: 0.9059 - val_accuracy: 0.6983\n",
            " F1 micro : 0.6983333333333334\n",
            "Epoch 8/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.8673 - accuracy: 0.7186 - val_loss: 0.8597 - val_accuracy: 0.7250\n",
            " F1 micro : 0.7250000000000001\n",
            "Epoch 9/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.8162 - accuracy: 0.7457 - val_loss: 0.8058 - val_accuracy: 0.7267\n",
            " F1 micro : 0.7266666666666666\n",
            "Epoch 10/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.7548 - accuracy: 0.7586 - val_loss: 0.7446 - val_accuracy: 0.7583\n",
            " F1 micro : 0.7583333333333333\n",
            "Epoch 11/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.7242 - accuracy: 0.7679 - val_loss: 0.6986 - val_accuracy: 0.7717\n",
            " F1 micro : 0.7716666666666666\n",
            "Epoch 12/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.6736 - accuracy: 0.7900 - val_loss: 0.6847 - val_accuracy: 0.7733\n",
            " F1 micro : 0.7733333333333333\n",
            "Epoch 13/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.6345 - accuracy: 0.7929 - val_loss: 0.6253 - val_accuracy: 0.7867\n",
            " F1 micro : 0.7866666666666666\n",
            "Epoch 14/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.6037 - accuracy: 0.8036 - val_loss: 0.6087 - val_accuracy: 0.7933\n",
            " F1 micro : 0.7933333333333333\n",
            "Epoch 15/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5647 - accuracy: 0.8129 - val_loss: 0.5805 - val_accuracy: 0.7967\n",
            " F1 micro : 0.7966666666666665\n",
            "Epoch 16/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5516 - accuracy: 0.8293 - val_loss: 0.5608 - val_accuracy: 0.8367\n",
            " F1 micro : 0.8366666666666667\n",
            "Epoch 17/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5386 - accuracy: 0.8243 - val_loss: 0.5734 - val_accuracy: 0.8000\n",
            " F1 micro : 0.8000000000000002\n",
            "Epoch 18/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5400 - accuracy: 0.8250 - val_loss: 0.5592 - val_accuracy: 0.8117\n",
            " F1 micro : 0.8116666666666666\n",
            "Epoch 19/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.8436 - val_loss: 0.5199 - val_accuracy: 0.8317\n",
            " F1 micro : 0.8316666666666667\n",
            "Epoch 20/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4888 - accuracy: 0.8471 - val_loss: 0.4973 - val_accuracy: 0.8283\n",
            " F1 micro : 0.8283333333333334\n",
            "Epoch 21/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4693 - accuracy: 0.8443 - val_loss: 0.4851 - val_accuracy: 0.8300\n",
            " F1 micro : 0.83\n",
            "Epoch 22/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4542 - accuracy: 0.8564 - val_loss: 0.4855 - val_accuracy: 0.8517\n",
            " F1 micro : 0.8516666666666667\n",
            "Epoch 23/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4418 - accuracy: 0.8650 - val_loss: 0.4752 - val_accuracy: 0.8350\n",
            " F1 micro : 0.835\n",
            "Epoch 24/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4301 - accuracy: 0.8543 - val_loss: 0.4482 - val_accuracy: 0.8467\n",
            " F1 micro : 0.8466666666666667\n",
            "Epoch 25/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4242 - accuracy: 0.8671 - val_loss: 0.4477 - val_accuracy: 0.8467\n",
            " F1 micro : 0.8466666666666667\n",
            "Epoch 26/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4204 - accuracy: 0.8707 - val_loss: 0.4644 - val_accuracy: 0.8583\n",
            " F1 micro : 0.8583333333333333\n",
            "Epoch 27/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4177 - accuracy: 0.8686 - val_loss: 0.4378 - val_accuracy: 0.8650\n",
            " F1 micro : 0.865\n",
            "Epoch 28/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3931 - accuracy: 0.8786 - val_loss: 0.4369 - val_accuracy: 0.8633\n",
            " F1 micro : 0.8633333333333333\n",
            "Epoch 29/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3883 - accuracy: 0.8793 - val_loss: 0.4156 - val_accuracy: 0.8733\n",
            " F1 micro : 0.8733333333333333\n",
            "Epoch 30/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3859 - accuracy: 0.8771 - val_loss: 0.3922 - val_accuracy: 0.8733\n",
            " F1 micro : 0.8733333333333333\n",
            "Epoch 31/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3774 - accuracy: 0.8807 - val_loss: 0.4123 - val_accuracy: 0.8783\n",
            " F1 micro : 0.8783333333333333\n",
            "Epoch 32/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3770 - accuracy: 0.8736 - val_loss: 0.3629 - val_accuracy: 0.8900\n",
            " F1 micro : 0.89\n",
            "Epoch 33/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3379 - accuracy: 0.9000 - val_loss: 0.3725 - val_accuracy: 0.8900\n",
            " F1 micro : 0.89\n",
            "Epoch 34/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3364 - accuracy: 0.8971 - val_loss: 0.3777 - val_accuracy: 0.8817\n",
            " F1 micro : 0.8816666666666667\n",
            "Epoch 35/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3315 - accuracy: 0.8979 - val_loss: 0.3475 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 36/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3286 - accuracy: 0.8979 - val_loss: 0.3576 - val_accuracy: 0.8883\n",
            " F1 micro : 0.8883333333333333\n",
            "Epoch 37/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3082 - accuracy: 0.9107 - val_loss: 0.3873 - val_accuracy: 0.8583\n",
            " F1 micro : 0.8583333333333333\n",
            "Epoch 38/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3180 - accuracy: 0.8993 - val_loss: 0.3869 - val_accuracy: 0.8933\n",
            " F1 micro : 0.8933333333333333\n",
            "Epoch 39/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3207 - accuracy: 0.9007 - val_loss: 0.3316 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 40/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.3148 - accuracy: 0.9050 - val_loss: 0.3363 - val_accuracy: 0.9000\n",
            " F1 micro : 0.9\n",
            "Epoch 41/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2906 - accuracy: 0.9150 - val_loss: 0.3336 - val_accuracy: 0.8917\n",
            " F1 micro : 0.8916666666666667\n",
            "Epoch 42/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2780 - accuracy: 0.9171 - val_loss: 0.2993 - val_accuracy: 0.9100\n",
            " F1 micro : 0.91\n",
            "Epoch 43/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.9057 - val_loss: 0.3606 - val_accuracy: 0.8817\n",
            " F1 micro : 0.8816666666666667\n",
            "Epoch 44/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2912 - accuracy: 0.9071 - val_loss: 0.3240 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 45/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2671 - accuracy: 0.9214 - val_loss: 0.2853 - val_accuracy: 0.9133\n",
            " F1 micro : 0.9133333333333333\n",
            "Epoch 46/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2599 - accuracy: 0.9164 - val_loss: 0.2975 - val_accuracy: 0.9000\n",
            " F1 micro : 0.9\n",
            "Epoch 47/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2591 - accuracy: 0.9214 - val_loss: 0.2813 - val_accuracy: 0.9167\n",
            " F1 micro : 0.9166666666666666\n",
            "Epoch 48/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2534 - accuracy: 0.9271 - val_loss: 0.2804 - val_accuracy: 0.9117\n",
            " F1 micro : 0.9116666666666666\n",
            "Epoch 49/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2514 - accuracy: 0.9286 - val_loss: 0.2836 - val_accuracy: 0.9100\n",
            " F1 micro : 0.91\n",
            "Epoch 50/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2437 - accuracy: 0.9279 - val_loss: 0.2961 - val_accuracy: 0.8967\n",
            " F1 micro : 0.8966666666666666\n",
            "Epoch 51/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2474 - accuracy: 0.9286 - val_loss: 0.3063 - val_accuracy: 0.9083\n",
            " F1 micro : 0.9083333333333333\n",
            "Epoch 52/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2448 - accuracy: 0.9307 - val_loss: 0.2897 - val_accuracy: 0.9167\n",
            " F1 micro : 0.9166666666666666\n",
            "Epoch 53/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2465 - accuracy: 0.9186 - val_loss: 0.3150 - val_accuracy: 0.8883\n",
            " F1 micro : 0.8883333333333333\n",
            "Epoch 54/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2229 - accuracy: 0.9307 - val_loss: 0.2740 - val_accuracy: 0.9183\n",
            " F1 micro : 0.9183333333333333\n",
            "Epoch 55/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2376 - accuracy: 0.9300 - val_loss: 0.2672 - val_accuracy: 0.9200\n",
            " F1 micro : 0.92\n",
            "Epoch 56/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2298 - accuracy: 0.9336 - val_loss: 0.2918 - val_accuracy: 0.9133\n",
            " F1 micro : 0.9133333333333333\n",
            "Epoch 57/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2443 - accuracy: 0.9286 - val_loss: 0.3041 - val_accuracy: 0.9133\n",
            " F1 micro : 0.9133333333333333\n",
            "Epoch 58/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.9357 - val_loss: 0.2733 - val_accuracy: 0.9050\n",
            " F1 micro : 0.905\n",
            "Epoch 59/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2299 - accuracy: 0.9250 - val_loss: 0.2711 - val_accuracy: 0.9183\n",
            " F1 micro : 0.9183333333333333\n",
            "Epoch 60/60\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.2178 - accuracy: 0.9371 - val_loss: 0.2602 - val_accuracy: 0.9133\n",
            " F1 micro : 0.9133333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88f0185150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxlEVyIYaNpt"
      },
      "source": [
        "<pre>\n",
        "Now we have\n",
        "\n",
        "Train data: X_train_spectrogram and y_train  \n",
        "Test data: X_test_spectrogram and y_test   \n",
        "\n",
        "We will create a LSTM model which takes this input. \n",
        "\n",
        "Task:\n",
        "\n",
        "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
        "2. Average the output of every time step and give this to the Dense layer of any size. \n",
        "(ex: Output from LSTM will be  (#., time_steps, features) average the output of every time step i.e, you should get (#.,time_steps) \n",
        "and then pass to dense layer )\n",
        "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
        "4. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
        "5. make sure that it won't overfit. \n",
        "6. You are free to include any regularization\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSl8ZOXjaNqJ"
      },
      "source": [
        "### 3. data augmentation  \n",
        "<pre>\n",
        "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
        "\n",
        "There are two types of augmentation:\n",
        "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
        "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR4JSEDgaNqK"
      },
      "source": [
        "## generating augmented data. \n",
        "def generate_augmented_data(file_path):\n",
        "    augmented_data = []\n",
        "    samples = load_wav(file_path,get_duration=False)\n",
        "    for time_value in [0.7, 1, 1.3]:\n",
        "        for pitch_value in [-1, 0, 1]:\n",
        "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
        "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
        "            augmented_data.append(final_data)\n",
        "    return augmented_data"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac4mf_aZYVob",
        "outputId": "311f50e0-ed35-428f-e116-c1fc38e8d9ee"
      },
      "source": [
        "x_train_data_aug = []\n",
        "\n",
        "for path in X_train:\n",
        "  aug_temp = generate_augmented_data(path)\n",
        "  x_train_data_aug.extend(aug_temp)\n",
        "\n",
        "x_train_data_aug = np.array(x_train_data_aug)\n",
        "\n",
        "y_train_data_aug = []\n",
        "\n",
        "for i in y_train:\n",
        "  c = [i]*9\n",
        "  y_train_data_aug.extend(c)\n",
        "\n",
        "y_train_data_aug = np.array(y_train_data_aug)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYZEGgzMbGA_"
      },
      "source": [
        "X_train_pad_seq1 = []\n",
        "for li in x_train_data_aug:\n",
        "  if len(li) < max_length:\n",
        "    li = li.tolist()\n",
        "    a = [0]*(max_length - len(li))\n",
        "    li.extend(a)\n",
        "    X_train_pad_seq1.append(li)\n",
        "\n",
        "  else:\n",
        "    li = li.tolist()\n",
        "    X_train_pad_seq1.append(li[0:max_length])\n",
        "\n",
        "X_train_pad_seq1 = np.array(X_train_pad_seq1)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyOlevm0LM7I"
      },
      "source": [
        "X_train_mask1 = np.array([(i > 0).tolist()for i in X_train_pad_seq1])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKexdqkHIGKb"
      },
      "source": [
        "##MODEL :- 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFHveG08b7yn",
        "outputId": "cd5288b3-5c8f-46d8-b23a-8f6ce28c07fe"
      },
      "source": [
        "## as discussed above, please write the LSTM\n",
        "\n",
        "lstm = LSTM(units = 100,activation=\"tanh\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0))\n",
        "\n",
        "input_layer = Input(shape=(X_train_pad_seq.shape[1],1),dtype=float)\n",
        "input_mask = Input(shape=(X_train_mask.shape[1],1),dtype=bool)\n",
        "LSTM_layer  = lstm(inputs=input_layer,mask=input_mask)\n",
        "dense = Dense(50,activation=\"relu\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0))(LSTM_layer)\n",
        "output_1 = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(dense)\n",
        "\n",
        "model = Model(inputs = [input_layer,input_mask],outputs = output_1)\n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.sparse_categorical_crossentropy,metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 17640, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 100)          40800       input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 50)           5050        lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           510         dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 46,360\n",
            "Trainable params: 46,360\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lat5bg4cRUu",
        "outputId": "d07bbd04-e0fc-4cdd-f44d-5d3117d9ec60"
      },
      "source": [
        "X_train_pad_seq1.shape, X_train_mask1.shape, y_train_data_aug.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12600, 17640), (12600, 17640), (12600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOGz2SBdcb1h",
        "outputId": "e824d155-65a7-4267-b663-036d130dca8b"
      },
      "source": [
        "X_test_pad_seq.shape,X_test_mask.shape,y_test.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((600, 17640), (600, 17640), (600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAIzMSlGcDMd",
        "outputId": "25212dd3-fc10-431d-f0a8-2882f9e59b01"
      },
      "source": [
        "model.fit(x=[X_train_pad_seq1,X_train_mask1],y=y_train_data_aug,validation_data=([X_test_pad_seq,X_test_mask],y_test),\n",
        "            epochs=2,batch_size=10,steps_per_epoch=len(X_train_mask)//10 , callbacks=metrics)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "140/140 [==============================] - 44s 298ms/step - loss: 2.3046 - accuracy: 0.1150 - val_loss: 2.3017 - val_accuracy: 0.1033\n",
            " F1 micro : 0.10000000000000002\n",
            "Epoch 2/2\n",
            "140/140 [==============================] - 41s 291ms/step - loss: 2.3012 - accuracy: 0.1155 - val_loss: 2.2994 - val_accuracy: 0.1250\n",
            " F1 micro : 0.10000000000000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f89097e5ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZckytZsraNqk"
      },
      "source": [
        "As discussed above, for one data point, we will get 9 augmented data points.  \n",
        "\n",
        "Split data into train and test (80-20 split)\n",
        "\n",
        "We have 2000 data points(1600 train points, 400 test points) \n",
        "\n",
        "Do augmentation only on train data, after augmentation we will get 14400 train points. \n",
        "\n",
        "do the above steps i.e training with raw data and spectrogram data with augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKudgh_0JDjs"
      },
      "source": [
        "##MODEL :- 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9kHQ6x3QUJn"
      },
      "source": [
        "X_train_spectrogram1 = [convert_to_spectrogram(row) for row in X_train_pad_seq1]\n",
        "X_train_spectrogram1 = np.array(X_train_spectrogram1)\n",
        "\n",
        "X_test_spectrogram = [convert_to_spectrogram(row) for row in X_test_pad_seq]\n",
        "X_test_spectrogram = np.array(X_test_spectrogram)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6OrjvpDQZEC",
        "outputId": "1fe53418-db5e-454e-f666-c82796b0ca96"
      },
      "source": [
        "## as discussed above, please write the LSTM\n",
        "\n",
        "lstm = LSTM(units = 100,activation=\"tanh\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0),return_sequences=True)\n",
        "\n",
        "input_layer = Input(shape=(X_test_spectrogram[0].shape),dtype=float)\n",
        "LSTM_layer  = lstm(inputs=input_layer)\n",
        "glo_avg = tf.keras.layers.GlobalAveragePooling1D(data_format='channels_first')(LSTM_layer)\n",
        "dense = Dense(50,activation=\"relu\",kernel_initializer=tf.keras.initializers.he_uniform(seed=0))(glo_avg)\n",
        "output_1 = Dense(10,activation='softmax',kernel_initializer=tf.keras.initializers.GlorotUniform(seed=0))(dense)\n",
        "\n",
        "model = Model(inputs = [input_layer],outputs = output_1)\n",
        "model.compile(optimizer='adam',loss = tf.keras.losses.sparse_categorical_crossentropy,metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 64, 35)]          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64, 100)           54400     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                3250      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 58,160\n",
            "Trainable params: 58,160\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT24XDC5QnS-",
        "outputId": "ca4e1759-2798-4802-dd6c-7337696baef5"
      },
      "source": [
        "X_train_spectrogram1.shape , X_test_spectrogram.shape ,y_train_data_aug.shape,y_test.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12600, 64, 35), (600, 64, 35), (12600,), (600,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx1F1n4aJrG8",
        "outputId": "3e8bb74f-f980-4c31-e0be-2d3b1e64cc9c"
      },
      "source": [
        "model.fit(x=X_train_spectrogram1,y=y_train_data_aug,validation_data=(X_test_spectrogram,y_test),\n",
        "            epochs=60,batch_size=10,steps_per_epoch=len(X_train_spectrogram1)//10, callbacks=metrics1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.8588 - accuracy: 0.7082 - val_loss: 0.6784 - val_accuracy: 0.7700\n",
            " F1 micro : 0.7699999999999999\n",
            "Epoch 2/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.6708 - accuracy: 0.7670 - val_loss: 0.5384 - val_accuracy: 0.8433\n",
            " F1 micro : 0.8433333333333335\n",
            "Epoch 3/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.5804 - accuracy: 0.7985 - val_loss: 0.5305 - val_accuracy: 0.8183\n",
            " F1 micro : 0.8183333333333332\n",
            "Epoch 4/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.5177 - accuracy: 0.8254 - val_loss: 0.4310 - val_accuracy: 0.8733\n",
            " F1 micro : 0.8733333333333333\n",
            "Epoch 5/60\n",
            "1260/1260 [==============================] - 6s 4ms/step - loss: 0.4789 - accuracy: 0.8363 - val_loss: 0.4122 - val_accuracy: 0.8667\n",
            " F1 micro : 0.8666666666666667\n",
            "Epoch 6/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.4582 - accuracy: 0.8421 - val_loss: 0.3508 - val_accuracy: 0.9067\n",
            " F1 micro : 0.9066666666666666\n",
            "Epoch 7/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.4234 - accuracy: 0.8554 - val_loss: 0.3487 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 8/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.4096 - accuracy: 0.8614 - val_loss: 0.3308 - val_accuracy: 0.9000\n",
            " F1 micro : 0.9\n",
            "Epoch 9/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3868 - accuracy: 0.8648 - val_loss: 0.3121 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 10/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3816 - accuracy: 0.8696 - val_loss: 0.2856 - val_accuracy: 0.9200\n",
            " F1 micro : 0.92\n",
            "Epoch 11/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3710 - accuracy: 0.8729 - val_loss: 0.2847 - val_accuracy: 0.9167\n",
            " F1 micro : 0.9166666666666666\n",
            "Epoch 12/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3742 - accuracy: 0.8723 - val_loss: 0.3288 - val_accuracy: 0.8883\n",
            " F1 micro : 0.8883333333333333\n",
            "Epoch 13/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3735 - accuracy: 0.8704 - val_loss: 0.3156 - val_accuracy: 0.9167\n",
            " F1 micro : 0.9166666666666666\n",
            "Epoch 14/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3634 - accuracy: 0.8752 - val_loss: 0.2834 - val_accuracy: 0.9200\n",
            " F1 micro : 0.92\n",
            "Epoch 15/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3566 - accuracy: 0.8784 - val_loss: 0.3203 - val_accuracy: 0.8933\n",
            " F1 micro : 0.8933333333333333\n",
            "Epoch 16/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3524 - accuracy: 0.8794 - val_loss: 0.3073 - val_accuracy: 0.9050\n",
            " F1 micro : 0.905\n",
            "Epoch 17/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3625 - accuracy: 0.8770 - val_loss: 0.2614 - val_accuracy: 0.9267\n",
            " F1 micro : 0.9266666666666666\n",
            "Epoch 18/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3465 - accuracy: 0.8799 - val_loss: 0.2728 - val_accuracy: 0.9217\n",
            " F1 micro : 0.9216666666666666\n",
            "Epoch 19/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3411 - accuracy: 0.8832 - val_loss: 0.2924 - val_accuracy: 0.9000\n",
            " F1 micro : 0.9\n",
            "Epoch 20/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3458 - accuracy: 0.8840 - val_loss: 0.3417 - val_accuracy: 0.8833\n",
            " F1 micro : 0.8833333333333333\n",
            "Epoch 21/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3417 - accuracy: 0.8807 - val_loss: 0.3261 - val_accuracy: 0.8850\n",
            " F1 micro : 0.885\n",
            "Epoch 22/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3372 - accuracy: 0.8880 - val_loss: 0.2792 - val_accuracy: 0.9100\n",
            " F1 micro : 0.91\n",
            "Epoch 23/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3488 - accuracy: 0.8816 - val_loss: 0.2817 - val_accuracy: 0.9133\n",
            " F1 micro : 0.9133333333333333\n",
            "Epoch 24/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3355 - accuracy: 0.8818 - val_loss: 0.3114 - val_accuracy: 0.8933\n",
            " F1 micro : 0.8933333333333333\n",
            "Epoch 25/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3308 - accuracy: 0.8885 - val_loss: 0.2801 - val_accuracy: 0.9017\n",
            " F1 micro : 0.9016666666666667\n",
            "Epoch 26/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3323 - accuracy: 0.8853 - val_loss: 0.2433 - val_accuracy: 0.9233\n",
            " F1 micro : 0.9233333333333333\n",
            "Epoch 27/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3227 - accuracy: 0.8880 - val_loss: 0.2594 - val_accuracy: 0.9250\n",
            " F1 micro : 0.925\n",
            "Epoch 28/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3321 - accuracy: 0.8860 - val_loss: 0.2433 - val_accuracy: 0.9250\n",
            " F1 micro : 0.925\n",
            "Epoch 29/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3150 - accuracy: 0.8901 - val_loss: 0.2713 - val_accuracy: 0.9117\n",
            " F1 micro : 0.9116666666666666\n",
            "Epoch 30/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3080 - accuracy: 0.8915 - val_loss: 0.2531 - val_accuracy: 0.9200\n",
            " F1 micro : 0.92\n",
            "Epoch 31/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3283 - accuracy: 0.8872 - val_loss: 0.2568 - val_accuracy: 0.9183\n",
            " F1 micro : 0.9183333333333333\n",
            "Epoch 32/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3217 - accuracy: 0.8850 - val_loss: 0.2574 - val_accuracy: 0.9217\n",
            " F1 micro : 0.9216666666666666\n",
            "Epoch 33/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3013 - accuracy: 0.8945 - val_loss: 0.2621 - val_accuracy: 0.9100\n",
            " F1 micro : 0.91\n",
            "Epoch 34/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3002 - accuracy: 0.8937 - val_loss: 0.2990 - val_accuracy: 0.9000\n",
            " F1 micro : 0.9\n",
            "Epoch 35/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3237 - accuracy: 0.8867 - val_loss: 0.3120 - val_accuracy: 0.9017\n",
            " F1 micro : 0.9016666666666667\n",
            "Epoch 36/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3382 - accuracy: 0.8806 - val_loss: 0.2423 - val_accuracy: 0.9200\n",
            " F1 micro : 0.92\n",
            "Epoch 37/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3277 - accuracy: 0.8874 - val_loss: 0.2859 - val_accuracy: 0.9017\n",
            " F1 micro : 0.9016666666666667\n",
            "Epoch 38/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3227 - accuracy: 0.8868 - val_loss: 0.3133 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 39/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3225 - accuracy: 0.8893 - val_loss: 0.2612 - val_accuracy: 0.9150\n",
            " F1 micro : 0.915\n",
            "Epoch 40/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3208 - accuracy: 0.8894 - val_loss: 0.2501 - val_accuracy: 0.9200\n",
            " F1 micro : 0.92\n",
            "Epoch 41/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3137 - accuracy: 0.8908 - val_loss: 0.2897 - val_accuracy: 0.8917\n",
            " F1 micro : 0.8916666666666667\n",
            "Epoch 42/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3168 - accuracy: 0.8898 - val_loss: 0.2742 - val_accuracy: 0.9017\n",
            " F1 micro : 0.9016666666666667\n",
            "Epoch 43/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3085 - accuracy: 0.8944 - val_loss: 0.2851 - val_accuracy: 0.8983\n",
            " F1 micro : 0.8983333333333333\n",
            "Epoch 44/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3218 - accuracy: 0.8852 - val_loss: 0.2854 - val_accuracy: 0.9050\n",
            " F1 micro : 0.905\n",
            "Epoch 45/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3122 - accuracy: 0.8933 - val_loss: 0.2476 - val_accuracy: 0.9300\n",
            " F1 micro : 0.93\n",
            "Epoch 46/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3165 - accuracy: 0.8887 - val_loss: 0.2942 - val_accuracy: 0.9017\n",
            " F1 micro : 0.9016666666666667\n",
            "Epoch 47/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3293 - accuracy: 0.8815 - val_loss: 0.3269 - val_accuracy: 0.8950\n",
            " F1 micro : 0.895\n",
            "Epoch 48/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3031 - accuracy: 0.8945 - val_loss: 0.2534 - val_accuracy: 0.9133\n",
            " F1 micro : 0.9133333333333333\n",
            "Epoch 49/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3108 - accuracy: 0.8884 - val_loss: 0.3208 - val_accuracy: 0.8933\n",
            " F1 micro : 0.8933333333333333\n",
            "Epoch 50/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3004 - accuracy: 0.8960 - val_loss: 0.2774 - val_accuracy: 0.9083\n",
            " F1 micro : 0.9083333333333333\n",
            "Epoch 51/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3290 - accuracy: 0.8819 - val_loss: 0.2377 - val_accuracy: 0.9233\n",
            " F1 micro : 0.9233333333333333\n",
            "Epoch 52/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3024 - accuracy: 0.8936 - val_loss: 0.2176 - val_accuracy: 0.9333\n",
            " F1 micro : 0.9333333333333333\n",
            "Epoch 53/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.3064 - accuracy: 0.8891 - val_loss: 0.2896 - val_accuracy: 0.8917\n",
            " F1 micro : 0.8916666666666667\n",
            "Epoch 54/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2920 - accuracy: 0.8966 - val_loss: 0.2735 - val_accuracy: 0.8950\n",
            " F1 micro : 0.895\n",
            "Epoch 55/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2871 - accuracy: 0.8989 - val_loss: 0.2077 - val_accuracy: 0.9283\n",
            " F1 micro : 0.9283333333333333\n",
            "Epoch 56/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2881 - accuracy: 0.8986 - val_loss: 0.2770 - val_accuracy: 0.9083\n",
            " F1 micro : 0.9083333333333333\n",
            "Epoch 57/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2837 - accuracy: 0.9013 - val_loss: 0.2557 - val_accuracy: 0.9117\n",
            " F1 micro : 0.9116666666666666\n",
            "Epoch 58/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2888 - accuracy: 0.8971 - val_loss: 0.2583 - val_accuracy: 0.9117\n",
            " F1 micro : 0.9116666666666666\n",
            "Epoch 59/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2925 - accuracy: 0.8969 - val_loss: 0.2464 - val_accuracy: 0.9017\n",
            " F1 micro : 0.9016666666666667\n",
            "Epoch 60/60\n",
            "1260/1260 [==============================] - 6s 5ms/step - loss: 0.2817 - accuracy: 0.8991 - val_loss: 0.2276 - val_accuracy: 0.9283\n",
            " F1 micro : 0.9283333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f88b4e99b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRIkQ_SPxAKV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}